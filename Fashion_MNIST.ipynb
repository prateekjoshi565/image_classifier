{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_Y.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_Y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fe9320fb4e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAACuCAYAAACr3LH6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe932196908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_X[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(train_Y[0]))\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(test_X[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(test_Y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape(-1, 28,28, 1)\n",
    "test_X = test_X.reshape(-1, 28,28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "\n",
    "# recaling pixel values in the range 0 to 1\n",
    "train_X = train_X / 255. \n",
    "test_X = test_X / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: 9\n",
      "After conversion to one-hot: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Change the labels from categorical to one-hot encoding\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "\n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', train_Y[111])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[111])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 15\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = Sequential()\n",
    "my_model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(28,28,1),padding='same'))\n",
    "my_model.add(LeakyReLU(alpha=0.3))\n",
    "my_model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "my_model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "my_model.add(LeakyReLU(alpha=0.3))\n",
    "my_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "my_model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "my_model.add(LeakyReLU(alpha=0.3))                  \n",
    "my_model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "my_model.add(Flatten())\n",
    "my_model.add(Dense(128, activation='linear'))\n",
    "my_model.add(LeakyReLU(alpha=0.3))                  \n",
    "my_model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                 optimizer=keras.optimizers.Adam(), \n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "48000/48000 [==============================] - 69s 1ms/step - loss: 0.4582 - acc: 0.8346 - val_loss: 0.3188 - val_acc: 0.8866\n",
      "Epoch 2/15\n",
      "48000/48000 [==============================] - 71s 1ms/step - loss: 0.2864 - acc: 0.8959 - val_loss: 0.2694 - val_acc: 0.9017\n",
      "Epoch 3/15\n",
      "48000/48000 [==============================] - 73s 2ms/step - loss: 0.2420 - acc: 0.9104 - val_loss: 0.2551 - val_acc: 0.9076\n",
      "Epoch 4/15\n",
      "48000/48000 [==============================] - 72s 1ms/step - loss: 0.2111 - acc: 0.9224 - val_loss: 0.2413 - val_acc: 0.9133\n",
      "Epoch 5/15\n",
      "48000/48000 [==============================] - 69s 1ms/step - loss: 0.1843 - acc: 0.9319 - val_loss: 0.2368 - val_acc: 0.9177\n",
      "Epoch 6/15\n",
      "48000/48000 [==============================] - 70s 1ms/step - loss: 0.1610 - acc: 0.9402 - val_loss: 0.2309 - val_acc: 0.9187\n",
      "Epoch 7/15\n",
      "48000/48000 [==============================] - 70s 1ms/step - loss: 0.1412 - acc: 0.9487 - val_loss: 0.2467 - val_acc: 0.9163\n",
      "Epoch 8/15\n",
      "48000/48000 [==============================] - 71s 1ms/step - loss: 0.1230 - acc: 0.9544 - val_loss: 0.2517 - val_acc: 0.9219\n",
      "Epoch 9/15\n",
      "48000/48000 [==============================] - 73s 2ms/step - loss: 0.1058 - acc: 0.9611 - val_loss: 0.2627 - val_acc: 0.9197\n",
      "Epoch 10/15\n",
      "48000/48000 [==============================] - 72s 2ms/step - loss: 0.0903 - acc: 0.9670 - val_loss: 0.2692 - val_acc: 0.9203\n",
      "Epoch 11/15\n",
      "48000/48000 [==============================] - 73s 2ms/step - loss: 0.0777 - acc: 0.9716 - val_loss: 0.3084 - val_acc: 0.9157\n",
      "Epoch 12/15\n",
      "48000/48000 [==============================] - 74s 2ms/step - loss: 0.0691 - acc: 0.9742 - val_loss: 0.3508 - val_acc: 0.9099\n",
      "Epoch 13/15\n",
      "48000/48000 [==============================] - 75s 2ms/step - loss: 0.0601 - acc: 0.9781 - val_loss: 0.3278 - val_acc: 0.9230\n",
      "Epoch 14/15\n",
      "48000/48000 [==============================] - 74s 2ms/step - loss: 0.0505 - acc: 0.9811 - val_loss: 0.3909 - val_acc: 0.9117\n",
      "Epoch 15/15\n",
      "48000/48000 [==============================] - 73s 2ms/step - loss: 0.0503 - acc: 0.9816 - val_loss: 0.3886 - val_acc: 0.9163\n"
     ]
    }
   ],
   "source": [
    "my_model_train = my_model.fit(train_X, train_label, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 508us/step\n"
     ]
    }
   ],
   "source": [
    "test_eval = my_model.evaluate(test_X, test_Y_one_hot, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Loss:  0.415009062642\n",
      "Test Dataset Accuracy:  0.9126\n"
     ]
    }
   ],
   "source": [
    "print('Test Dataset Loss: ', test_eval[0])\n",
    "print('Test Dataset Accuracy: ', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = my_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = np.argmax(np.round(predicted_classes), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.where(predicted_label == test_Y)[0]\n",
    "incorrect = np.where(predicted_label != test_Y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9122 items classified correctly\n",
      "878 items misclassified\n"
     ]
    }
   ],
   "source": [
    "print(str(len(correct)) + \" items classified correctly\")\n",
    "print(str(len(incorrect)) + \" items misclassified\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
